{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "* https://archive.org/download/stackexchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# postFile = \"../StackExchangedData/3dprinting.stackexchange.com/Posts.xml\"\n",
    "postFile = \"../StackExchangedData/ai.stackexchange.com/Posts.xml\"\n",
    "# postFile = \"../StackExchangedData/anime.stackexchange.com/Posts.xml\"\n",
    "# postFile = \"../StackExchangedData/askubuntu.com/Posts.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree\n",
    "e = xml.etree.ElementTree.parse(postFile).getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "421\n"
     ]
    }
   ],
   "source": [
    "titles = []\n",
    "for atype in e.findall('row'):\n",
    "    title = atype.get('Title')\n",
    "    if title is not None:\n",
    "        titles.append(title)\n",
    "        \n",
    "print(len(titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['what', 'is', '``', 'backprop', \"''\", '?'],\n",
      " ['how', 'does', 'noise', 'affect', 'generalization', '?'],\n",
      " ['how',\n",
      "  'to',\n",
      "  'find',\n",
      "  'the',\n",
      "  'optimal',\n",
      "  'number',\n",
      "  'of',\n",
      "  'neurons',\n",
      "  'per',\n",
      "  'layer',\n",
      "  '?']]\n",
      "[[('what', 'WP'),\n",
      "  ('is', 'VBZ'),\n",
      "  ('``', '``'),\n",
      "  ('backprop', 'NN'),\n",
      "  (\"''\", \"''\"),\n",
      "  ('?', '.')],\n",
      " [('how', 'WRB'),\n",
      "  ('does', 'VBZ'),\n",
      "  ('noise', 'VB'),\n",
      "  ('affect', 'VB'),\n",
      "  ('generalization', 'NN'),\n",
      "  ('?', '.')],\n",
      " [('how', 'WRB'),\n",
      "  ('to', 'TO'),\n",
      "  ('find', 'VB'),\n",
      "  ('the', 'DT'),\n",
      "  ('optimal', 'JJ'),\n",
      "  ('number', 'NN'),\n",
      "  ('of', 'IN'),\n",
      "  ('neurons', 'NNS'),\n",
      "  ('per', 'IN'),\n",
      "  ('layer', 'NN'),\n",
      "  ('?', '.')]]\n"
     ]
    }
   ],
   "source": [
    "_word_tokenize = nltk.TreebankWordTokenizer().tokenize\n",
    "\n",
    "sentences = [_word_tokenize(title.lower()) for title in titles]\n",
    "tagged_sentences = [nltk.pos_tag(sent) for sent in sentences]\n",
    "pprint.pprint(sentences[:3])\n",
    "pprint.pprint(tagged_sentences[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alltitles = \" \".join(titles).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is \"backprop\"? how does noise affect generalization? how to find the optimal number of neurons per layer? how to program ai in mindstorms on the intelligent agent definition of intelligence why does stephen hawking say \"artificial intelligence will kill us all\"? what is fuzzy logic? can a single neural network handle recognizing two types of objects, or should it be split into two smaller networks? is the turing test, or any of its variants, a reliable test of artificial intelligence? what is early stopping? what is the concept of the technological singularity? what are the methods of optimizing overfitted models? how could emotional intelligence be implemented? is a genetic algorithm an example of artificial intelligence? what is the difference between artificial intelligence and machine learning? to what extent can quantum computers help to develop artificial intelligence? what is a markov chain and how can it be used in creating artificial intelligence? what is the \"dropout\" te\n"
     ]
    }
   ],
   "source": [
    "print(alltitles[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# POS tagger\n",
    "tokens = nltk.word_tokenize(alltitles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what', 'is', '``', 'backprop', \"''\", '?', 'how', 'does', 'noise', 'affect']\n"
     ]
    }
   ],
   "source": [
    "# Tokenized Text\n",
    "print(tokens[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('what', 'WP'), ('is', 'VBZ'), ('``', '``'), ('backprop', 'NN'), (\"''\", \"''\"), ('?', '.'), ('how', 'WRB'), ('does', 'VBZ'), ('noise', 'VB'), ('affect', 'VB'), ('generalization', 'NN'), ('?', '.'), ('how', 'WRB'), ('to', 'TO'), ('find', 'VB')]\n"
     ]
    }
   ],
   "source": [
    "# Tagged Text\n",
    "tagged_text = nltk.pos_tag(tokens)\n",
    "print(tagged_text[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n",
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n",
      "NNPS: noun, proper, plural\n",
      "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
      "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
      "    Apache Apaches Apocrypha ...\n",
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n"
     ]
    }
   ],
   "source": [
    "#Documentation\n",
    "nltk.help.upenn_tagset('NN.*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homonyms: each of two or more words having the same spelling but different meanings and origins (e.g., pole1 and pole2); a homograph.\n",
    "\n",
    "* Over - Preposition\n",
    "* The - Determiner\n",
    "* A - Determiner\n",
    "* And - Coordinating Conjunction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert tokens to NLTK Text\n",
    "text = nltk.Text(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "networks\n"
     ]
    }
   ],
   "source": [
    "# Find similar words\n",
    "text.similar(\"network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genetic an conditions are a moves they\n"
     ]
    }
   ],
   "source": [
    "text.similar(\"the\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image does\n"
     ]
    }
   ],
   "source": [
    "text.similar(\"artificial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('fly', 'NN')\n"
     ]
    }
   ],
   "source": [
    "sample_tagged_token = nltk.tag.str2tuple('fly/NN')\n",
    "print(sample_tagged_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([',', 'POS', 'VBZ', 'VB', 'EX', 'JJS', 'JJ', \"''\", '.', 'PRP$', 'RBS', 'IN', 'VBN', '(', 'WRB', 'RBR', 'RP', '$', 'NNS', 'RB', 'WDT', 'NNP', 'DT', 'TO', 'VBP', ')', 'VBD', 'VBG', 'WP', '``', ':', 'CD', 'JJR', 'SYM', 'NN', 'PRP', 'CC', 'MD'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most common tags in the text\n",
    "tag_fd = nltk.FreqDist(tag for (word, tag) in tagged_text)\n",
    "tag_fd.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tag_fd.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Adjectives as modifiers (The large pizza)\n",
    "* As predicates (The pizza is large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#nltk.app.concordance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NN', 'NNS', 'NNP']\n"
     ]
    }
   ],
   "source": [
    "cfd = nltk.ConditionalFreqDist((tag, word) for (word, tag) in tagged_text if tag.startswith('NN'))\n",
    "print(cfd.conditions())\n",
    "nounConditions = cfd.conditions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['resources', 'ways', 'types', 'regulations', 'attempts', 'chat/sms', 'aspects', 'units', 'brainwaves', 'mars']\n"
     ]
    }
   ],
   "source": [
    "cfd['NNS'].keys()\n",
    "print(list(cfd['NNS'].keys())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find the words with the given tag\n",
    "def findtags(tag_prefix, tagged_text, retCount):\n",
    "    cfd = nltk.ConditionalFreqDist((tag, word) for (word, tag) in tagged_text if tag.startswith(tag_prefix))\n",
    "    return dict((tag, list(cfd[tag].keys())[:retCount]) for tag in cfd.conditions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NN': ['theory', 't-shirt', 'technique', 'feasibility', 'emotion', 'program', 'self-driving', 'blue', 'sky', 'valkyrie'], 'NNS': ['resources', 'ways', 'types', 'regulations', 'attempts', 'chat/sms', 'aspects', 'units', 'brainwaves', 'mars'], 'NNP': ['/', \"'pong-v0\", 'minsky', '[', 'von', 'xor']}\n"
     ]
    }
   ],
   "source": [
    "tagdict = findtags('NN', tagged_text, 10)\n",
    "print(tagdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('help', 'to', 'develop'), ('used', 'to', 'tackle'), ('considered', 'to', 'be'), ('developed', 'to', 'test'), ('continue', 'to', 'be'), ('used', 'to', 'augment'), ('designed', 'to', 'run'), ('attempt', 'to', 'use'), ('required', 'to', 'simulate'), ('aiming', 'to', 'achieve')]\n"
     ]
    }
   ],
   "source": [
    "# Three word phrases\n",
    "def process(sentence):\n",
    "    retVal = []\n",
    "    for (w1, t1), (w2, t2), (w3, t3) in nltk.trigrams(sentence):\n",
    "        if (t1.startswith('V') and t2 == 'TO' and t3.startswith('V')):\n",
    "            retVal.append((w1, w2, w3))\n",
    "    return retVal\n",
    "\n",
    "print(process(tagged_text)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN ['ai', 'intelligence', 'network', 'learning', 'machine', 'language', 'work', 'algorithm', 'difference', 'recognition', 'image', 'algorithms', 'research', 'game', 'problem', 'reinforcement', 'way', 'program', 'number', 'search', 'computer', 'test', 'brain', 'function', 'argument', 'kind', 'training', 'car', 'system', 'detection', 'concept', 'model', 'cnn', 'programming', 'technique', 'purpose', 'definition', 'input', 'dream', 'ais', 'theory', 'sentient', 'environment', 'someone', 'representation', 'development', 'state', 'agi', 'efficiency', 'net', 'level', 'text', 'learn', 'agent', 'space', 'processing', 'power', 'backpropagation', 'framework', 'time', 'death', 'sort', 'go', 'life', 'place', 'amount', 'classification', 'use', 'application', 'position', 'tree', 'context', 'action', 'decision', 'feature', 'state/action', 'solution', 'mlp', 'generation', 'iq', 'world', 'carlo', 'error', 'summarization', 'human', 'asimov', 'emotion', 'example', 'halting', 'chatbot', 'measure', 'real-time', 'optimization', 'dnn', 'developer', 'radar', 'practice', 'stack', 'something', 'trap', 'start', 'part', 'domain', 'video', 'watson', 'value', 'anybody', 'code', 'step', 'layer', 'pre-training', 'stop', 'vacuum', 'sequence', 'collapse', 'flexibility', 'quantum', 'decompiler', 'respect', 'anyone', 'stay', 'belief', 'memory', 'intent', 'python', 'capability', 'prolog', 'try', 'dependency', 'vgdl', 'deal', 'curiosity', 'boundary', 'prerequisite', 't-shirt', 'existence', 'piece', 'q-learning', 'wi', 'incompletion', 'consent', 'size', 'machina', 'kill', 'fitness', 'mixture', 'humanity', 'graphs', 'control', 'coherent']\n",
      "NNS ['networks', 'cars', 'systems', 'problems', 'data', 'methods', 'neurons', 'approaches', 'images', 'questions', 'ai', 'algorithms', 'models', 'humans', 'advantages', 'layers', 'examples', 'languages', 'games', 'machines', 'requirements', 'rights', 'patterns', 'actions', 'features', 'tests', 'programs', 'robots', 'people', 'laws', 'states', 'chatbots', 'capabilities', 'results', 'jobs', 'applications', 'hyper-heuristics', 'chips', 'moves', 'differences', 'challenges', 'computers', 'mars', 'variants', 'nodes', 'techniques', 'studies', 'objects', 'resources', 'components', 'convnets', 'settings', 'designs', 'references', 'years', 'alternatives', 'vectors', 'bots', 'journals', 'judges', 'orientations', 'supplements', 'capsules', 'constraints', 'terms', 'operations', 'cleaners', 'numbers', 'books', 'successes', 'pictures', 'units', 'gofai', 'phrases', 'agents', 'resnets', 'engines', 'robotics', 'datasets', 'intelligences', 'spaces', 'encyclopedias', 'researchers', 'nn', 'microchips', 'goals', 'autoencoders', 'mindstorms', 'flaws', 'architectures', 'considerations', 'linguistics', 'dogs', 'answers', 'attempts', 'sentences', 'hallucinations', 'users', 'decisions', 'kinds', 'reports', 'boundaries', 'limits', 'drives', 'incompletenes', 'pedestrians', 'gestures', 'functions', 'brains', 'parts', 'metrics', 'projects', 'signs', 'strategies', 'pilots', 'ways', 'exists', 'gaps', 'screenplays', 'chat/sms', 'hawkins', 'benefits', 'connections', 'ethics', 'means', 'diagnoses', 'equations', 'characters', 'squares', 'experts', 'classes', 'students', 'discoveries', 'scientists', 'frameworks', 'issues', 'solvers', 'dimensions', 'dangers', 'postures', 'tools', 'clothes', 'expressions', 'choices', 'schemes', 'types', 'leaders', 'flights', 'epigenetics', 'perceptrons']\n",
      "NNP ['von', 'xor', '[', 'minsky', \"'pong-v0\", '/']\n"
     ]
    }
   ],
   "source": [
    "# Find the most common Nouns and proper Nouns\n",
    "word_tag_fd = nltk.FreqDist(tagged_text)\n",
    "\n",
    "# http://www.nltk.org/book/ch05.html\n",
    "for cond in nounConditions:\n",
    "    print(cond, [wt[0] for (wt, _) in word_tag_fd.most_common() if wt[1] == cond][:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('?', '.'), 368),\n",
       " (('the', 'DT'), 147),\n",
       " (('to', 'TO'), 129),\n",
       " (('of', 'IN'), 116),\n",
       " (('is', 'VBZ'), 106)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd = nltk.FreqDist(tagged_text)\n",
    "fd.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Adjectives\n",
    "cfd = nltk.ConditionalFreqDist((tag, word) for (word, tag) in tagged_text if tag.startswith(\"JJ\"))\n",
    "adjConditions = cfd.conditions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JJ ['artificial', 'neural', 'ai', 'deep', 'human', 'possible', 'genetic', 'good', 'other', 'strong']\n",
      "JJS ['best', 'most', 'lowest']\n",
      "JJR ['more', 'less', 'better', 'classifier', 'smaller']\n"
     ]
    }
   ],
   "source": [
    "for adjCond in adjConditions:\n",
    "    print(adjCond, [wt[0] for (wt, _) in word_tag_fd.most_common() if wt[1] == adjCond][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['JJ', 'NN', 'DT', 'IN', 'VB', 'VBG', '.', 'CC', 'WP', 'VBZ', 'POS', \"''\", 'NNS', '(', 'PRP$', 'VBP', ')', 'TO', '``', 'JJS', 'CD', 'VBN', 'WRB', 'RB', 'WDT', 'MD', 'RP', 'NNP', 'VBD', 'JJR']\n"
     ]
    }
   ],
   "source": [
    "word_tag_pairs = nltk.bigrams(tagged_text)\n",
    "noun_preceders = [a[1] for (a, b) in word_tag_pairs if b[1] == 'NN']\n",
    "fdist = nltk.FreqDist(noun_preceders)\n",
    "tags1 = [tag for (tag, _) in fdist.most_common()]\n",
    "print(tags1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JJ 261\n",
      "NN 154\n",
      "DT 147\n",
      "IN 111\n",
      "VB 42\n",
      "VBG 30\n",
      ". 17\n",
      "CC 15\n",
      "WP 11\n",
      "VBZ 10\n",
      "POS 9\n",
      "'' 8\n",
      "NNS 8\n",
      "( 6\n",
      "PRP$ 6\n",
      "VBP 6\n",
      ") 6\n",
      "TO 4\n",
      "`` 4\n",
      "JJS 3\n",
      "CD 3\n",
      "VBN 2\n",
      "WRB 2\n",
      "RB 2\n",
      "WDT 2\n",
      "MD 2\n",
      "RP 1\n",
      "NNP 1\n",
      "VBD 1\n",
      "JJR 1\n"
     ]
    }
   ],
   "source": [
    "for k,v in fdist.most_common():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((('artificial', 'JJ'), ('intelligence', 'NN')), 34), ((('neural', 'JJ'), ('network', 'NN')), 22), ((('genetic', 'JJ'), ('algorithm', 'NN')), 5), ((('human', 'JJ'), ('brain', 'NN')), 4), ((('deep', 'JJ'), ('learning', 'NN')), 3), ((('genetic', 'JJ'), ('algorithms', 'NN')), 3), ((('ai', 'JJ'), ('program', 'NN')), 2), ((('artificial', 'JJ'), ('life', 'NN')), 2), ((('real', 'JJ'), ('world', 'NN')), 2), ((('natural', 'JJ'), ('language', 'NN')), 2)]\n"
     ]
    }
   ],
   "source": [
    "# Most common JJ+NN pairs\n",
    "word_tag_pairs = nltk.bigrams(tagged_text)\n",
    "JJbeforeNN = [(a,b) for (a, b) in word_tag_pairs if b[1] == 'NN' and a[1] == 'JJ']\n",
    "fdist = nltk.FreqDist(JJbeforeNN)\n",
    "print(fdist.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((('artificial', 'JJ'), ('neural', 'JJ'), ('network', 'NN')), 2), ((('intensive', 'JJ'), ('local', 'JJ'), ('search', 'NN')), 1), ((('internal', 'JJ'), ('dialectical', 'JJ'), ('approach', 'NN')), 1), ((('feedforward', 'JJ'), ('neural', 'JJ'), ('network', 'NN')), 1), ((('artificial', 'JJ'), ('general', 'JJ'), ('intelligence', 'NN')), 1), ((('distributed', 'JJ'), ('lossy', 'JJ'), ('compression', 'NN')), 1), ((('mdp', 'JJ'), ('intelligent', 'JJ'), ('vision', 'NN')), 1), ((('ios/android', 'JJ'), ('neural', 'JJ'), ('network', 'NN')), 1), ((('true', 'JJ'), ('artificial', 'JJ'), ('intelligence', 'NN')), 1), ((('autonomous', 'JJ'), ('robotic', 'JJ'), ('vacuum', 'NN')), 1)]\n"
     ]
    }
   ],
   "source": [
    "word_tag_triples = nltk.trigrams(tagged_text)\n",
    "JJJJNN = [(a,b,c) for (a, b, c) in word_tag_triples if c[1] == 'NN' and b[1] == 'JJ' and a[1] == 'JJ']\n",
    "fdist = nltk.FreqDist(JJJJNN)\n",
    "print(fdist.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | D         |\n",
      "    | E I J N V |\n",
      "    | T N J N B |\n",
      "----+-----------+\n",
      "DET |<3>. . . . |\n",
      " IN | .<1>. . . |\n",
      " JJ | . .<.>1 . |\n",
      " NN | . . .<3>1 |\n",
      " VB | . . . .<1>|\n",
      "----+-----------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "from nltk.metrics import ConfusionMatrix\n",
    "ref  = 'DET NN VB DET JJ NN NN IN DET NN'.split()\n",
    "tagged = 'DET VB VB DET NN NN NN IN DET NN'.split()\n",
    "cm = ConfusionMatrix(ref, tagged)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((('a', 'DT'), ('neural', 'JJ'), ('network', 'NN')), 6), ((('a', 'DT'), ('genetic', 'JJ'), ('algorithm', 'NN')), 3), ((('any', 'DT'), ('artificial', 'JJ'), ('intelligence', 'NN')), 2), ((('the', 'DT'), ('real', 'JJ'), ('world', 'NN')), 2), ((('an', 'DT'), ('ai', 'JJ'), ('program', 'NN')), 2), ((('the', 'DT'), ('recent', 'JJ'), ('advent', 'NN')), 1), ((('a', 'DT'), ('neural', 'JJ'), ('net', 'NN')), 1), ((('the', 'DT'), ('chinese', 'JJ'), ('room', 'NN')), 1), ((('any', 'DT'), ('textual', 'JJ'), ('captcha', 'NN')), 1), ((('the', 'DT'), ('only', 'JJ'), ('way', 'NN')), 1)]\n"
     ]
    }
   ],
   "source": [
    "word_tag_triples = nltk.trigrams(tagged_text)\n",
    "DTJJNN = [(a,b,c) for (a, b, c) in word_tag_triples if c[1] == 'NN' and b[1] == 'JJ' and a[1] == 'DT']\n",
    "fdist = nltk.FreqDist(DTJJNN)\n",
    "print(fdist.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4122\n",
      "[('what', 'WP'), ('is', 'VBZ'), ('``', '``'), Tree('NP', [('backprop', 'NN')]), (\"''\", \"''\"), ('?', '.'), ('how', 'WRB'), ('does', 'VBZ'), ('noise', 'VB'), ('affect', 'VB'), Tree('NP', [('generalization', 'NN')]), ('?', '.'), ('how', 'WRB'), ('to', 'TO'), ('find', 'VB')]\n"
     ]
    }
   ],
   "source": [
    "grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "result = cp.parse(tagged_text)\n",
    "print(len(result))\n",
    "print(result[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ai', 70), ('intelligence', 49), ('network', 28), ('networks', 26), ('learning', 18), ('machine', 14), ('algorithms', 13), ('language', 12), ('work', 12), ('cars', 10)]\n"
     ]
    }
   ],
   "source": [
    "# Most Frequent words\n",
    "fdist1 = nltk.FreqDist(w for (w, t) in tagged_text if t.startswith(\"NN\"))\n",
    "print(fdist1.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n",
      "[['how', 'to', 'program', 'ai', 'in', 'mindstorms'],\n",
      " ['can', 'the', 'iq', 'of', 'an', 'ai', 'program', 'be', 'measured', '?'],\n",
      " ['what',\n",
      "  'are',\n",
      "  'the',\n",
      "  'main',\n",
      "  'problems',\n",
      "  'hindering',\n",
      "  'current',\n",
      "  'ai',\n",
      "  'development',\n",
      "  '?'],\n",
      " ['is',\n",
      "  'lisp',\n",
      "  'still',\n",
      "  'being',\n",
      "  'used',\n",
      "  'to',\n",
      "  'tackle',\n",
      "  'ai',\n",
      "  'problems',\n",
      "  '?'],\n",
      " ['what', 'are', 'some', 'examples', 'of', 'statistical', 'ai', '?']]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "questionsWithMostCommonWord = [sent for sent in sentences if 'ai' in sent]\n",
    "print(len(questionsWithMostCommonWord))\n",
    "pprint.pprint(questionsWithMostCommonWord[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Graph x=the most common words, y = the occurance in sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('what', 'WP'), ('is', 'VBZ'), ('``', '``'), ('backprop', 'NN'), (\"''\", \"''\"), ('?', '.'), ('how', 'WRB'), ('does', 'VBZ'), ('noise', 'VB'), ('affect', 'VB'), ('generalization', 'NN'), ('?', '.'), ('how', 'WRB'), ('to', 'TO'), ('find', 'VB'), ('the', 'DT'), ('optimal', 'JJ'), ('number', 'NN'), ('of', 'IN'), ('neurons', 'NNS'), ('per', 'IN'), ('layer', 'NN'), ('?', '.'), ('how', 'WRB'), ('to', 'TO'), ('program', 'NN'), ('ai', 'NN'), ('in', 'IN'), ('mindstorms', 'NNS'), ('on', 'IN'), ('the', 'DT'), ('intelligent', 'JJ'), ('agent', 'NN'), ('definition', 'NN'), ('of', 'IN'), ('intelligence', 'NN'), ('why', 'WRB'), ('does', 'VBZ'), ('stephen', 'VB'), ('hawking', 'VBG'), ('say', 'VB'), ('``', '``'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('will', 'MD'), ('kill', 'VB'), ('us', 'PRP'), ('all', 'DT'), (\"''\", \"''\"), ('?', '.')]\n"
     ]
    }
   ],
   "source": [
    "# Named entities\n",
    "print(nltk.ne_chunk(tagged_text)[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
